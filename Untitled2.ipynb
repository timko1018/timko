{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"authorship_tag":"ABX9TyMxh+HtP4ENXhM3gy+BVjc+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"seBv_cxAX8ks","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598086741125,"user_tz":-480,"elapsed":1337,"user":{"displayName":"柯承廷","photoUrl":"","userId":"04344198974468338104"}}},"source":["#coding=utf-8\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalMaxPooling2D"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"r2PL8brwYBJ_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1598086742143,"user_tz":-480,"elapsed":2336,"user":{"displayName":"柯承廷","photoUrl":"","userId":"04344198974468338104"}},"outputId":"64f8601a-3fdb-42c4-8e98-af9cdced4706"},"source":["batch_size = 32 \n","num_classes = 10\n","epochs = 1600\n","data_augmentation = True\n","\n","# The data, shuffled and split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rQkFqbl1YHpM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598086742147,"user_tz":-480,"elapsed":2320,"user":{"displayName":"柯承廷","photoUrl":"","userId":"04344198974468338104"}},"outputId":"e6a0f67b-df36-411a-f2ac-a957aae8061d"},"source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(48, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(48, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(80, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(80, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(80, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(80, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(80, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(128, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(128, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(128, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(128, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(128, (3, 3), padding='same',\n","                                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(GlobalMaxPooling2D())\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(500))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.25))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary ()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_45 (Conv2D)           (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_51 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_46 (Conv2D)           (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","activation_52 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_47 (Conv2D)           (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","activation_53 (Activation)   (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_48 (Conv2D)           (None, 32, 32, 48)        13872     \n","_________________________________________________________________\n","activation_54 (Activation)   (None, 32, 32, 48)        0         \n","_________________________________________________________________\n","conv2d_49 (Conv2D)           (None, 32, 32, 48)        20784     \n","_________________________________________________________________\n","activation_55 (Activation)   (None, 32, 32, 48)        0         \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 16, 16, 48)        0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 16, 16, 48)        0         \n","_________________________________________________________________\n","conv2d_50 (Conv2D)           (None, 16, 16, 80)        34640     \n","_________________________________________________________________\n","activation_56 (Activation)   (None, 16, 16, 80)        0         \n","_________________________________________________________________\n","conv2d_51 (Conv2D)           (None, 16, 16, 80)        57680     \n","_________________________________________________________________\n","activation_57 (Activation)   (None, 16, 16, 80)        0         \n","_________________________________________________________________\n","conv2d_52 (Conv2D)           (None, 16, 16, 80)        57680     \n","_________________________________________________________________\n","activation_58 (Activation)   (None, 16, 16, 80)        0         \n","_________________________________________________________________\n","conv2d_53 (Conv2D)           (None, 16, 16, 80)        57680     \n","_________________________________________________________________\n","activation_59 (Activation)   (None, 16, 16, 80)        0         \n","_________________________________________________________________\n","conv2d_54 (Conv2D)           (None, 16, 16, 80)        57680     \n","_________________________________________________________________\n","activation_60 (Activation)   (None, 16, 16, 80)        0         \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 8, 8, 80)          0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 8, 8, 80)          0         \n","_________________________________________________________________\n","conv2d_55 (Conv2D)           (None, 8, 8, 128)         92288     \n","_________________________________________________________________\n","activation_61 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_56 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_62 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_57 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_63 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_58 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_64 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_59 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_65 (Activation)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","global_max_pooling2d_3 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 500)               64500     \n","_________________________________________________________________\n","activation_66 (Activation)   (None, 500)               0         \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 500)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                5010      \n","_________________________________________________________________\n","activation_67 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 1,071,542\n","Trainable params: 1,071,542\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jht3pg2oYLAp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c18a7887-c8a6-4e6c-d09a-56a906ac4e78"},"source":["# initiate RMSprop optimizer\n","opt = keras.optimizers.Adam(lr=0.0001)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","                            optimizer=opt,\n","                            metrics=['accuracy'])\n","\n","print(\"train____________\")\n","model.fit(x_train,y_train,epochs=600,batch_size=128,)\n","print(\"test_____________\")\n","loss,acc=model.evaluate(X_test,y_test)\n","print(\"loss=\",loss)\n","print(\"accuracy=\",acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train____________\n","Epoch 1/600\n","391/391 [==============================] - 45s 115ms/step - loss: 2.0185 - accuracy: 0.2256\n","Epoch 2/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.7500 - accuracy: 0.3302\n","Epoch 3/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.6168 - accuracy: 0.3847\n","Epoch 4/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.5048 - accuracy: 0.4367\n","Epoch 5/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.4180 - accuracy: 0.4775\n","Epoch 6/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.3364 - accuracy: 0.5113\n","Epoch 7/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.2720 - accuracy: 0.5400\n","Epoch 8/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.2264 - accuracy: 0.5606\n","Epoch 9/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.1689 - accuracy: 0.5824\n","Epoch 10/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.1281 - accuracy: 0.5971\n","Epoch 11/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.0944 - accuracy: 0.6099\n","Epoch 12/600\n","391/391 [==============================] - 44s 113ms/step - loss: 1.0630 - accuracy: 0.6217\n","Epoch 13/600\n","391/391 [==============================] - 44s 114ms/step - loss: 1.0246 - accuracy: 0.6351\n","Epoch 14/600\n","391/391 [==============================] - 44s 114ms/step - loss: 1.0001 - accuracy: 0.6442\n","Epoch 15/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.9716 - accuracy: 0.6569\n","Epoch 16/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.9465 - accuracy: 0.6660\n","Epoch 17/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.9199 - accuracy: 0.6753\n","Epoch 18/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.8914 - accuracy: 0.6830\n","Epoch 19/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.8702 - accuracy: 0.6945\n","Epoch 20/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.8509 - accuracy: 0.6984\n","Epoch 21/600\n","391/391 [==============================] - 45s 114ms/step - loss: 0.8310 - accuracy: 0.7094\n","Epoch 22/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.8060 - accuracy: 0.7154\n","Epoch 23/600\n","391/391 [==============================] - 45s 114ms/step - loss: 0.7843 - accuracy: 0.7239\n","Epoch 24/600\n","391/391 [==============================] - 45s 114ms/step - loss: 0.7663 - accuracy: 0.7304\n","Epoch 25/600\n","391/391 [==============================] - 45s 114ms/step - loss: 0.7534 - accuracy: 0.7365\n","Epoch 26/600\n","391/391 [==============================] - 45s 114ms/step - loss: 0.7244 - accuracy: 0.7453\n","Epoch 27/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.7113 - accuracy: 0.7513\n","Epoch 28/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.6982 - accuracy: 0.7545\n","Epoch 29/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.6745 - accuracy: 0.7622\n","Epoch 30/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.6620 - accuracy: 0.7676\n","Epoch 31/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.6430 - accuracy: 0.7759\n","Epoch 32/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.6396 - accuracy: 0.7778\n","Epoch 33/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.6254 - accuracy: 0.7814\n","Epoch 34/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.6108 - accuracy: 0.7841\n","Epoch 35/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.5947 - accuracy: 0.7904\n","Epoch 36/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.5788 - accuracy: 0.7979\n","Epoch 37/600\n","391/391 [==============================] - 44s 113ms/step - loss: 0.5646 - accuracy: 0.8009\n","Epoch 38/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.5485 - accuracy: 0.8071\n","Epoch 39/600\n","391/391 [==============================] - 44s 114ms/step - loss: 0.5455 - accuracy: 0.8073\n","Epoch 40/600\n","228/391 [================>.............] - ETA: 18s - loss: 0.5219 - accuracy: 0.8164"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FjrjL7ZcYlPK","colab_type":"code","colab":{}},"source":["if not data_augmentation:\n","        print('Not using data augmentation.')\n","        model.fit(x_train, y_train,\n","                            batch_size=batch_size,\n","                            epochs=epochs,\n","                            validation_data=(x_test, y_test),\n","                            shuffle=True, callbacks=[tbCallBack])\n","else:\n","        print('Using real-time data augmentation.')\n","        # This will do preprocessing and realtime data augmentation:\n","        '''\n","        datagen = ImageDataGenerator(\n","                featurewise_center=False,  # set input mean to 0 over the dataset\n","                samplewise_center=False,  # set each sample mean to 0\n","                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","                samplewise_std_normalization=False,  # divide each input by its std\n","                zca_whitening=False,  # apply ZCA whitening\n","                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","                horizontal_flip=True,  # randomly flip images\n","                vertical_flip=False)  # randomly flip images\n","        '''\n","        datagen = ImageDataGenerator(\n","                featurewise_center=False,  # set input mean to 0 over the dataset\n","                samplewise_center=False,  # set each sample mean to 0\n","                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","                samplewise_std_normalization=False,  # divide each input by its std\n","                zca_whitening=False,  # apply ZCA whitening\n","                rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","                width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n","                height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n","                horizontal_flip=True,  # randomly flip images\n","                vertical_flip=False)  # randomly flip images\n","\n","\n","        # Compute quantities required for feature-wise normalization\n","        # (std, mean, and principal components if ZCA whitening is applied).\n","        datagen.fit(x_train)\n","\n","        # Fit the model on the batches generated by datagen.flow().\n","        model.fit_generator(datagen.flow(x_train, y_train,\n","                                                                         batch_size=batch_size),\n","                                                steps_per_epoch=x_train.shape[0] // batch_size,\n","                                                epochs=epochs,\n","                                                validation_data=(x_test, y_test), callbacks=[tbCallBack])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_cnPxizYrf6","colab_type":"code","colab":{}},"source":["if not data_augmentation:\n","        print('Not using data augmentation.')\n","        model.fit(x_train, y_train,\n","                            batch_size=batch_size,\n","                            epochs=epochs,\n","                            validation_data=(x_test, y_test),\n","                            shuffle=True, callbacks=[tbCallBack])\n","else:\n","        print('Using real-time data augmentation.')\n","        # This will do preprocessing and realtime data augmentation:\n","        '''\n","        datagen = ImageDataGenerator(\n","                featurewise_center=False,  # set input mean to 0 over the dataset\n","                samplewise_center=False,  # set each sample mean to 0\n","                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","                samplewise_std_normalization=False,  # divide each input by its std\n","                zca_whitening=False,  # apply ZCA whitening\n","                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","                horizontal_flip=True,  # randomly flip images\n","                vertical_flip=False)  # randomly flip images\n","        '''\n","        datagen = ImageDataGenerator(\n","                featurewise_center=False,  # set input mean to 0 over the dataset\n","                samplewise_center=False,  # set each sample mean to 0\n","                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","                samplewise_std_normalization=False,  # divide each input by its std\n","                zca_whitening=False,  # apply ZCA whitening\n","                rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","                width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n","                height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n","                horizontal_flip=True,  # randomly flip images\n","                vertical_flip=False)  # randomly flip images\n","\n","\n","        # Compute quantities required for feature-wise normalization\n","        # (std, mean, and principal components if ZCA whitening is applied).\n","        datagen.fit(x_train)\n","\n","        # Fit the model on the batches generated by datagen.flow().\n","        model.fit_generator(datagen.flow(x_train, y_train,\n","                                                                         batch_size=batch_size),\n","                                                steps_per_epoch=x_train.shape[0] // batch_size,\n","                                                epochs=epochs,\n","                                                validation_data=(x_test, y_test), callbacks=[tbCallBack])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6fX6YV-zYxmQ","colab_type":"code","colab":{}},"source":["config = model.get_config()\n","model = model.from_config(config)"],"execution_count":null,"outputs":[]}]}